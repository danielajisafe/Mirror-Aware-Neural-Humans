{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0e1d0",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fce925f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"DANBO-pytorch\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import plotly.io as pio\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import core.utils.skeletons as skeleton\n",
    "from core.load_data import generate_bullet_time\n",
    "from core.utils.extras import load_pickle, alpha_to_hip_1st\n",
    "from core.utils.skeleton_utils import plot_skeleton3d as danbo_plot_skeleton3d\n",
    "from core.utils.skeleton_utils import get_kp_bounding_cylinder, plot_bounding_cylinder\n",
    "\n",
    "pio.renderers.default = 'notebook' \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564d3b4",
   "metadata": {},
   "source": [
    "##### Load reconstructed 3D data - (replace with your own id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e190639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 25, 2]),\n",
       " torch.Size([2000, 25, 2]),\n",
       " torch.Size([2000, 25, 2]),\n",
       " torch.Size([2000, 26, 6]),\n",
       " torch.Size([2000, 26, 3, 3]),\n",
       " torch.Size([1, 25, 1, 1]),\n",
       " torch.Size([2000, 26, 3, 3]),\n",
       " torch.Size([1, 3, 3]),\n",
       " 2000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_name = \"Subj3\"\n",
    "# add reconstruction identifier below. Can be found in 'outputs/metrics.txt' e.g xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx_cam_0\n",
    "comb = \"cdaec2b9-6f15-45a1-8c25-778ce83089d9_cam_0\" # replace with your own id here for e.g subject 3\n",
    "iterations = 1999  # also encoded on the reconstruction result pickle file name\n",
    "\n",
    "id = comb.split(\"_cam_\")[0]\n",
    "view = cam = comb.split(\"_cam_\")[1]\n",
    "files = sorted(glob(f\"outputs/recon_results_no_gt2d_no_gtfocal/{view}/*{id}.pickle\"))\n",
    "\n",
    "kp3d, kp3d_h, proj2d_real, proj2d_virt, img_urls, v_view_h, r_view_h = [], [], [], [], [], [], []\n",
    "est_2d_real, est_2d_virt, rotation, theta, bf_build = [], [], [], [], []\n",
    "bone_orient_store, k_optim, bone_length = [], [], []\n",
    "p_dash_2d, p_2d, N_2d, normal_end_2d = [],[],[],[]\n",
    "ground_end_2d, refine_ground_end_2d, otho_end_2d = [],[], []\n",
    "l2ws, bf_positive, m_normal, g_normal = [], [], [], []\n",
    "chosen_frames, flipped_frames = [], []\n",
    "N3d, p3d, p_dash3d, otho = [],[],[], []\n",
    "real_feet_mask, virt_feet_mask = [], []\n",
    "A, A_dash, A_dash_tuple = [], [], []\n",
    "avg_D, plane_d = [], []\n",
    "\n",
    "# gather reconstructions \n",
    "for i in range(len(files)):\n",
    "    i = iterations\n",
    "    \n",
    "    filename = f\"outputs/recon_results_no_gt2d_no_gtfocal/{view}/{seq_name}_{view}_{i}_{i+1}iter_\"+\"{'A_dash': False, 'A_dash_fewer': False, 'K_op': True, 'bf_op': True, 'bf_build': True, 'n_g_single': True, 'n_m_single': True}_\"+f\"{id}.pickle\"\n",
    "    from_pickle = load_pickle(filename)\n",
    "    \n",
    "    kp3d.extend(from_pickle[\"kp3d\"]) \n",
    "    proj2d_real.extend(from_pickle[\"proj2d_real\"])\n",
    "    proj2d_virt.extend(from_pickle[\"proj2d_virt\"])\n",
    "    est_2d_real.extend(from_pickle[\"est_2d_real\"])\n",
    "    est_2d_virt.extend(from_pickle[\"est_2d_virt\"])\n",
    "    img_urls.extend(from_pickle[\"img_urls\"])\n",
    "    kp3d_h.extend(from_pickle[\"kp3d_h\"])\n",
    "    v_view_h.extend(from_pickle[\"v_view_h\"])\n",
    "    r_view_h.extend(from_pickle[\"r_view_h\"])\n",
    "    rotation.extend(from_pickle[\"optim_rotation3x3\"])\n",
    "    theta.extend(from_pickle[\"optim_theta\"]) \n",
    "    bf_build.extend(from_pickle[\"bf_build\"])\n",
    "    bone_orient_store.extend(from_pickle[\"b_orientation\"])\n",
    "    k_optim.extend(from_pickle[\"K_optim\"])\n",
    "    bf_positive.extend(from_pickle[\"bf_positive\"])\n",
    "    m_normal.extend(from_pickle[\"n_m\"])\n",
    "    g_normal.extend(from_pickle[\"n_g_mini\"])\n",
    "    otho.extend(from_pickle[\"otho\"])\n",
    "    N3d.extend(from_pickle[\"N3d\"])\n",
    "    p3d.extend(from_pickle[\"p3d\"])\n",
    "    p_dash3d.extend(from_pickle[\"p_dash3d\"])\n",
    "    flipped_frames.extend(from_pickle[\"flipped_frames\"])\n",
    "    A.extend(from_pickle[\"final_A\"])\n",
    "    A_dash.extend(from_pickle[\"final_A_dash\"])\n",
    "    avg_D.extend(from_pickle[\"avg_D\"])\n",
    "    plane_d.extend(from_pickle[\"plane_d\"])\n",
    "    \n",
    "    p_dash_2d.extend(from_pickle[\"p_dash_2d\"]); p_2d.extend(from_pickle[\"p_2d\"]); N_2d.extend(from_pickle[\"N_2d\"]);\n",
    "    normal_end_2d.extend(from_pickle[\"normal_end_2d\"]); ground_end_2d.extend(from_pickle[\"ground_end_2d\"])\n",
    "    refine_ground_end_2d.extend(from_pickle[\"refine_ground_end_2d\"]); otho_end_2d.extend(from_pickle[\"otho_end_2d\"])\n",
    "    l2ws.extend(from_pickle[\"l2ws\"])\n",
    "\n",
    "kp3d = torch.stack(kp3d)\n",
    "kp3d_h = torch.stack(kp3d_h)\n",
    "v_view_h = torch.stack(v_view_h)\n",
    "r_view_h = torch.stack(r_view_h)\n",
    "rotation_optim = torch.stack(rotation)\n",
    "theta_optim = torch.stack(theta)\n",
    "bf_build = torch.stack(bf_build)\n",
    "bone_orient_store = torch.stack(bone_orient_store)\n",
    "k_optim = torch.stack(k_optim).view(-1,3,3)\n",
    "bf_positive = torch.stack(bf_positive)\n",
    "A = torch.stack(A)\n",
    "A_dash = torch.stack(A_dash)\n",
    "avg_D = torch.stack(avg_D)\n",
    "plane_d = torch.stack(plane_d)\n",
    "\n",
    "chosen_frames = from_pickle[\"chosen_frames\"]\n",
    "initial_pose3d = from_pickle[\"initial_pose3d\"]\n",
    "\n",
    "p_dash_2d, p_2d = torch.stack(p_dash_2d), torch.stack(p_2d)\n",
    "N_2d, normal_end_2d = torch.stack(N_2d), torch.stack(normal_end_2d)\n",
    "ground_end_2d = torch.stack(ground_end_2d)\n",
    "refine_ground_end_2d = torch.stack(refine_ground_end_2d)\n",
    "otho_end_2d = torch.stack(otho_end_2d)\n",
    "l2ws = torch.stack(l2ws)\n",
    "m_normal = torch.stack(m_normal)\n",
    "g_normal = torch.stack(g_normal)\n",
    "N3d = torch.stack(N3d)\n",
    "p3d = torch.stack(p3d)\n",
    "otho = torch.stack(otho)\n",
    "p_dash3d = torch.stack(p_dash3d)\n",
    "\n",
    "proj2d_real = torch.stack(proj2d_real)\n",
    "proj2d_virt = torch.stack(proj2d_virt)\n",
    "est_2d_real = torch.stack(est_2d_real)\n",
    "est_2d_virt = torch.stack(est_2d_virt)\n",
    "\n",
    "proj2d_real.shape, proj2d_virt.shape, est_2d_real.shape, theta_optim.shape, rotation_optim.shape, \\\n",
    "bf_build.shape, bone_orient_store.shape, k_optim.shape, len(img_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055e7ff",
   "metadata": {},
   "source": [
    "##### extra accesories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c874223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_top = False\n",
    "\n",
    "if seq_name in [\"Subj3\"]:\n",
    "    add_top = True # for Tall people with longer head distance, e.g Subj3 \n",
    "d_size = 5\n",
    "add_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbc115cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 40, 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if add_top: # x2 \n",
    "    head_margin = 80; foot_margin = 40; side_margin = 80\n",
    "else:\n",
    "    head_margin = 40; foot_margin = 20; side_margin = 15\n",
    "head_margin, foot_margin, side_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475fc949",
   "metadata": {},
   "source": [
    "##### Last data stamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2ddea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-21-14'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H\") # uncomment \n",
    "timestamp = '2023-12-21-14' # please comment this out for real-timestamp\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abee575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', 'cdaec2b9-6f15-45a1-8c25-778ce83089d9_cam_0', '2023-12-21-14')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam, comb, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062dbe2",
   "metadata": {},
   "source": [
    "##### Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91c7b7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp3d_h_hipfirst = alpha_to_hip_1st(kp3d_h).detach().numpy() # same as real view\n",
    "\n",
    "v_view_h_hipfirst = alpha_to_hip_1st(v_view_h).detach().numpy()\n",
    "r_view_h_hipfirst = alpha_to_hip_1st(r_view_h).detach().numpy()\n",
    "B=v_view_h_hipfirst.shape[0]\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11c291bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.0\n",
    "test_set = int(B * ratio)\n",
    "train_set = B-test_set\n",
    "train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19d0f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseid = 0 #150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ffd83",
   "metadata": {},
   "source": [
    "##### create cylinders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f73af644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head direction: -y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2000, 5), -5.0286098, True, 3.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first convert to hip_first\n",
    "if add_top:\n",
    "    top_expand_ratio=3.\n",
    "else:\n",
    "    top_expand_ratio=1.\n",
    "    if seq_name == \"Daniel_normal\" or seq_name == \"Chunjin\":\n",
    "        top_expand_ratio=1.5\n",
    "\n",
    "extend_mm=250\n",
    "# global pose\n",
    "v_cylinder_params = get_kp_bounding_cylinder(v_view_h_hipfirst,\n",
    "                                               skel_type=skeleton.CMUSkeleton, extend_mm=extend_mm,\n",
    "                                               top_expand_ratio=top_expand_ratio,\n",
    "                                               head='-y')\n",
    "v_cylinder_params.shape, v_cylinder_params[poseid].min(), add_top, top_expand_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3b501",
   "metadata": {},
   "source": [
    "##### Create Betas and camera (same for all cams?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3714c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c2ws_demo():\n",
    "    \"\"\"unflipped as in A-NeRF\"\"\"\n",
    "    c2ws_real = torch.Tensor([[1,0,0,0],\n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]])\n",
    "    return c2ws_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812bb1ed",
   "metadata": {},
   "source": [
    "##### Configure settings: e.g add good top_margin_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b04c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_view = False\n",
    "generate_motion = True\n",
    "n_bullet = 90   \n",
    "clockwise = True\n",
    "bullet_ang=360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f527b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 4, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if generate_motion:\n",
    "    c2ws_real_temp = get_c2ws_demo().detach().numpy().astype(np.float32)\n",
    "    motion_c2ws = generate_bullet_time(c2ws_real_temp, n_views=n_bullet, bullet_ang=bullet_ang).reshape(-1, 4, 4)\n",
    "    # motion_c2ws = generate_bullet_time(c2ws_real_temp, n_views=n_bullet, bullet_ang=bullet_ang).transpose(1, 0, 2, 3).reshape(-1, 4, 4)\n",
    "    # back to tensor\n",
    "    motion_c2ws_tensor = torch.tensor(motion_c2ws)\n",
    "motion_c2ws_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85f2bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 26, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rotate_kps(motion_c2ws_tensor, n_bullet):\n",
    "    kps3d = torch.tensor(v_view_h_hipfirst[poseid:poseid+1])\n",
    "    kps_homo = torch.cat((kps3d, kps3d.new_ones(1).expand(*kps3d.shape[:-1], 1)), 2)\n",
    "    rotated_kps3d = torch.bmm(kps_homo.repeat(n_bullet,1,1), motion_c2ws_tensor).detach().numpy().astype(np.float32)\n",
    "    return rotated_kps3d\n",
    "\n",
    "rotated_kps3d = rotate_kps(motion_c2ws_tensor, n_bullet)\n",
    "rotated_kps3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fd0ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = f\"outputs/rotation/top_view_{top_view}/poseid_{poseid}\"\n",
    "fig_dir = f\"{fig_path}/{cam}/{comb}/{timestamp}\"\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dbe08",
   "metadata": {},
   "source": [
    "##### 3D rotation\n",
    "###### ref: https://community.plotly.com/t/rotating-3d-plots-with-plotly/34776/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17a23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"print {top_view}\")\n",
    "\n",
    "if top_view:\n",
    "    zoom_x=1; zoom_y=2; zoom_z=1\n",
    "    cam_eye_loc=[0,-1,0]\n",
    "    cam_up_orient=[1,1,0]\n",
    "\n",
    "else: # side_view\n",
    "    zoom_x=1; zoom_y=1; zoom_z=2\n",
    "    cam_eye_loc=[0,0,1.2]\n",
    "    cam_up_orient=[0,0,0]\n",
    "\n",
    "comb_idxs = np.concatenate([np.arange(45,90), np.arange(0,45)])\n",
    "for iter_, motion_idx in tqdm(enumerate(comb_idxs)):\n",
    "    fig = None\n",
    "    \n",
    "    fig= plot_bounding_cylinder(rotated_kps3d[motion_idx,:,:3], fig=fig, head=\"-y\")\n",
    "    fig= danbo_plot_skeleton3d(rotated_kps3d[motion_idx,:,:3], fig=fig,line_width=2,\\\n",
    "                          visible_x=False, visible_y=False, visible_z=False, \\\n",
    "                          cam_eye_loc=cam_eye_loc, zoom_x=zoom_x, zoom_y=zoom_y, zoom_z=zoom_z,\n",
    "                          cam_up_orient=cam_up_orient)\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(showticklabels=False),\n",
    "            yaxis = dict(showticklabels=False),\n",
    "            zaxis =dict(showticklabels=False)\n",
    "            ))\n",
    "    fig.write_image(f\"{fig_dir}/fig_{iter_:04d}.png\")\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef999cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from 'outputs/rotation/top_view_False/poseid_0/0/cdaec2b9-6f15-45a1-8c25-778ce83089d9_cam_0/2023-12-21-14/fig*.png':\n",
      "  Duration: 00:00:01.68, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 700x500, 50 fps, 50 tbr, 50 tbn, 50 tbc\n",
      "outputs/gif/3D_rotation.mp4: No such file or directory\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "outputs/gif/3D_rotation.mp4: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"outputs/gif\"\n",
    "to_vid = f\"ffmpeg -framerate 50 -pattern_type glob -i '{fig_dir}/fig*.png' -vf 'pad=ceil(iw/2)*2:ceil(ih/2)*2' -y -c:v libx264 -r 30 -pix_fmt yuv420p '{save_path}/3D_rotation.mp4'\"\n",
    "to_gif = f\"ffmpeg -i '{save_path}/3D_rotation.mp4' -pix_fmt yuv420p -loop 0 '{save_path}/3D_rotation.gif'\"\n",
    "os.system(to_vid)\n",
    "os.system(to_gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### single frame skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = None\n",
    "fig= danbo_plot_skeleton3d(v_view_h_hipfirst[poseid], fig=fig,line_width=2,\\\n",
    "                              visible_x=False, visible_y=False, visible_z=False, \\\n",
    "                              cam_eye_loc=cam_eye_loc, zoom_x=zoom_x, zoom_y=zoom_y, zoom_z=zoom_z,\n",
    "                              cam_up_orient=cam_up_orient)\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "        xaxis = dict(showticklabels=False),\n",
    "        yaxis = dict(showticklabels=False),\n",
    "        zaxis =dict(showticklabels=False)\n",
    "        )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f41cad8bb6e36ea3f157008fa54771a1421bc1dd9b556ccde98b3d71c8f4e292"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
